{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch(['http://127.0.0.1:9200'])\n",
    "\n",
    "drop_index = es_client.indices.create(index='search', ignore=400)\n",
    "create_index = es_client.indices.delete(index='search', ignore=[400, 404])\n",
    "\n",
    "def urlparser(title, url):\n",
    "    # scrape title\n",
    "    p = {}\n",
    "    post = title\n",
    "    page = requests.get(post).content\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    title_name = soup.title.string\n",
    "\n",
    "    # scrape tags\n",
    "    tag_names = []\n",
    "    desc = soup.findAll(attrs={\"property\":\"article:tag\"})\n",
    "    for x in xrange(len(desc)):\n",
    "        tag_names.append(desc[x-1]['content'].encode('utf-8'))\n",
    "\n",
    "    # payload for elasticsearch\n",
    "    doc = {\n",
    "        'date': time.strftime(\"%Y-%m-%d\"),\n",
    "        'title': title_name,\n",
    "        'tags': tag_names,\n",
    "        'url': url\n",
    "    }\n",
    "\n",
    "    # ingest payload into elasticsearch\n",
    "    res = es_client.index(index=\"blog-sysadmins\", doc_type=\"docs\", body=doc)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "sitemap_feed = 'https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research'\n",
    "page = requests.get(sitemap_feed)\n",
    "sitemap_index = BeautifulSoup(page.content, 'html.parser')\n",
    "urls = [element.text for element in sitemap_index.findAll('loc')]\n",
    "\n",
    "for x in urls:\n",
    "    urlparser(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FERET (facial recognition technology)\n",
      "\n",
      "11338 images of 1199 individuals in different positions and at different times.\n",
      "\n",
      "None.\n",
      "\n",
      "11,338\n",
      "\n",
      "Images\n",
      "\n",
      "Classification, face recognition\n",
      "\n",
      "CMU Pose, Illumination, and Expression (PIE)\n",
      "\n",
      "41,368 color images of 68 people in 13 different poses.\n",
      "\n",
      "Images labeled with expressions.\n",
      "\n",
      "41,368\n",
      "\n",
      "Images, text\n",
      "\n",
      "Classification, face recognition\n",
      "\n",
      "Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)\n",
      "\n",
      "7,356 video and audio recordings of 24 professional actors. 8 emotions each at two intensities.\n",
      "\n",
      "Files labelled with expression. Perceptual validation ratings provided by 319 raters.\n",
      "\n",
      "7,356\n",
      "\n",
      "Video, sound files\n",
      "\n",
      "Classification, face recognition, voice recognition\n",
      "\n",
      "SCFace\n",
      "\n",
      "Color images of faces at various angles.\n",
      "\n",
      "Location of facial features extracted. Coordinates of features given.\n",
      "\n",
      "4,160\n",
      "\n",
      "Images, text\n",
      "\n",
      "Classification, face recognition\n",
      "\n",
      "YouTube Faces DB\n",
      "\n",
      "Videos of 1,595 different people gathered from YouTube. Each clip is between 48 and 6,070 frames.\n",
      "\n",
      "Identity of those appearing in videos and descriptors.\n",
      "\n",
      "3,425 videos\n",
      "\n",
      "Video, text\n",
      "\n",
      "Video classification, face recognition\n",
      "\n",
      "300 videos in-the-Wild\n",
      "\n",
      "114 videos annotated for facial landmark tracking. The 68 landmark mark-up is applied to every frame.\n",
      "\n",
      "None\n",
      "\n",
      "114 videos, 218,000 frames.\n",
      "\n",
      "Video, annotation file.\n",
      "\n",
      "Facial landmark tracking.\n",
      "\n",
      "Grammatical Facial Expressions Dataset\n",
      "\n",
      "Grammatical Facial Expressions from Brazilian Sign Language.\n",
      "\n",
      "Microsoft Kinect features extracted.\n",
      "\n",
      "27,965\n",
      "\n",
      "Text\n",
      "\n",
      "Facial gesture recognition\n",
      "\n",
      "CMU Face Images Dataset\n",
      "\n",
      "Images of faces. Each person is photographed multiple times to capture different expressions.\n",
      "\n",
      "Labels and features.\n",
      "\n",
      "640\n",
      "\n",
      "Images, Text\n",
      "\n",
      "Face recognition\n",
      "\n",
      "Yale Face Database\n",
      "\n",
      "Faces of 15 individuals in 11 different expressions.\n",
      "\n",
      "Labels of expressions.\n",
      "\n",
      "165\n",
      "\n",
      "Images\n",
      "\n",
      "Face recognition\n",
      "\n",
      "Cohn-Kanade AU-Coded Expression Database\n",
      "\n",
      "Large database of images with labels for expressions.\n",
      "\n",
      "Tracking of certain facial features.\n",
      "\n",
      "500+ sequences\n",
      "\n",
      "Images, text\n",
      "\n",
      "Facial expression analysis\n",
      "\n",
      "FaceScrub\n",
      "\n",
      "Images of public figures scrubbed from image searching.\n",
      "\n",
      "Name and m/f annotation.\n",
      "\n",
      "107,818\n",
      "\n",
      "Images, text\n",
      "\n",
      "Face recognition\n",
      "\n",
      "BioID Face Database\n",
      "\n",
      "Images of faces with eye positions marked.\n",
      "\n",
      "Manually set eye positions.\n",
      "\n",
      "1521\n",
      "\n",
      "Images, text\n",
      "\n",
      "Face recognition\n",
      "\n",
      "Skin Segmentation Dataset\n",
      "\n",
      "Randomly sampled color values from face images.\n",
      "\n",
      "B, G, R, values extracted.\n",
      "\n",
      "245,057\n",
      "\n",
      "Text\n",
      "\n",
      "Segmentation, classification\n",
      "\n",
      "Bosphorus\n",
      "\n",
      "3D Face image database.\n",
      "\n",
      "34 action units and 6 expressions labeled; 24 facial landmarks labeled.\n",
      "\n",
      "4652\n",
      "\n",
      "\n",
      "Images, text\n",
      "\n",
      "\n",
      "Face recognition, classification\n",
      "\n",
      "UOY 3D-Face\n",
      "\n",
      "neutral face, 5 expressions: anger, happiness, sadness, eyes closed, eyebrows raised.\n",
      "\n",
      "labeling.\n",
      "\n",
      "5250\n",
      "\n",
      "\n",
      "Images, text\n",
      "\n",
      "\n",
      "Face recognition, classification\n",
      "\n",
      "CASIA\n",
      "\n",
      "Expressions: Anger, smile, laugh, surprise, closed eyes.\n",
      "\n",
      "None.\n",
      "\n",
      "4624\n",
      "\n",
      "\n",
      "Images, text\n",
      "\n",
      "\n",
      "Face recognition, classification\n",
      "\n",
      "CASIA\n",
      "\n",
      "Expressions: Anger Disgust Fear Happiness Sadness Surprise\n",
      "\n",
      "None.\n",
      "\n",
      "480\n",
      "\n",
      "Annotated Visible Spectrum and Near Infrared Video captures at 25 frames per second\n",
      "\n",
      "Face recognition, classification\n",
      "\n",
      "BU-3DFE\n",
      "\n",
      "neutral face, and 6 expressions: anger, happiness, sadness, surprise, disgust, fear (4 levels). 3D images extracted.\n",
      "\n",
      "None.\n",
      "\n",
      "2500\n",
      "\n",
      "Images, text\n",
      "\n",
      "Facial expression recognition, classification\n",
      "\n",
      "Face Recognition Grand Challenge Dataset\n",
      "\n",
      "Up to 22 samples for each subject. Expressions: anger, happiness, sadness, surprise, disgust, puffy. 3D Data.\n",
      "\n",
      "None.\n",
      "\n",
      "4007\n",
      "\n",
      "Images, text\n",
      "\n",
      "Face recognition, classification\n",
      "\n",
      "Gavabdb\n",
      "\n",
      "Up to 61 samples for each subject. Expressions neutral face, smile, frontal accentuated laugh, frontal random gesture. 3D images.\n",
      "\n",
      "None.\n",
      "\n",
      "549\n",
      "\n",
      "Images, text\n",
      "\n",
      "Face recognition, classification\n",
      "\n",
      "3D-RMA\n",
      "\n",
      "Up to 100 subjects, expressions mostly neutral. Several poses as well.\n",
      "\n",
      "None.\n",
      "\n",
      "9971\n",
      "\n",
      "Images, text\n",
      "\n",
      "Face recognition, classification\n",
      "\n",
      "SoF\n",
      "\n",
      "112 persons (66 males and 46 females) wear glasses under different illumination conditions.\n",
      "\n",
      "A set of synthetic filters (blur, occlusions, noise, and posterization ) with different level of difficulty.\n",
      "\n",
      "42,592 (2,662 original image Ã— 16 synthetic image)\n",
      "\n",
      "Images, Mat file\n",
      "\n",
      "Gender classification, face detection, face recognition, age estimation, and glasses detection\n",
      "\n",
      "IMDB-WIKI\n",
      "\n",
      "IMDB and Wikipedia face images with gender and age labels.\n",
      "\n",
      "None\n",
      "\n",
      "523,051\n",
      "\n",
      "Images\n",
      "\n",
      "Gender classification, face detection, face recognition, age estimation\n",
      "\n",
      "Human Motion DataBase (HMDB51)\n",
      "\n",
      "51 action categories, each containing at least 101 clips, extracted from a range of sources.\n",
      "\n",
      "None.\n",
      "\n",
      "6,766 video clips\n",
      "\n",
      "video clips\n",
      "\n",
      "Action classification\n",
      "\n",
      "TV Human Interaction Dataset\n",
      "\n",
      "Videos from 20 different TV shows for prediction social actions: handshake, high five, hug, kiss and none.\n",
      "\n",
      "None.\n",
      "\n",
      "6,766 video clips\n",
      "\n",
      "video clips\n",
      "\n",
      "Action prediction\n",
      "\n",
      "UT Interaction\n",
      "\n",
      "People acting out one of 6 actions (shake-hands, point, hug, push, kick, and punch) sometimes with multiple groups in the same video clip.\n",
      "\n",
      "None.\n",
      "\n",
      "120 video clips\n",
      "\n",
      "video clips\n",
      "\n",
      "Action prediction\n",
      "\n",
      "UT Kinect\n",
      "\n",
      "10 different people performing one of 6 actions (walk, sit down, stand up, pick up, carry, throw, push, pull, wave hands and clap hands) in an office setting.\n",
      "\n",
      "None.\n",
      "\n",
      "200 video clips with depth information at 15 frames per second\n",
      "\n",
      "video clips with depth information\n",
      "\n",
      "Action classification\n",
      "\n",
      "SBU Interact\n",
      "\n",
      "Seven participants performing one of 8 actions together (approaching, departing, pushing, kicking, punching, exchanging objects, hugging, and shaking hands) in an office setting.\n",
      "\n",
      "None.\n",
      "\n",
      "Around 300 interactions\n",
      "\n",
      "video clips with depth information\n",
      "\n",
      "Action classification\n",
      "\n",
      "Berkeley Multimodal Human Action Database (MHAD)\n",
      "\n",
      "Recordings of a single person performing 12 actions\n",
      "\n",
      "MoCap pre-processing\n",
      "\n",
      "660 action samples\n",
      "\n",
      "8 PhaseSpace Motion Capture, 2 Stereo Cameras, 4 Quad Cameras, 6 accelerometers, 4 microphones\n",
      "\n",
      "Action classification\n",
      "\n",
      "UCF 101 Dataset\n",
      "\n",
      "Self described as \"a dataset of 101 human actions classes from videos in the wild.\" Dataset is large with over 27 hours of video.\n",
      "\n",
      "Actions classified and labeled.\n",
      "\n",
      "13,000\n",
      "\n",
      "Video, images, text\n",
      "\n",
      "Classification, action detection\n",
      "\n",
      "THUMOS Dataset\n",
      "\n",
      "Large video dataset for action classification.\n",
      "\n",
      "Actions classified and labeled.\n",
      "\n",
      "45M frames of video\n",
      "\n",
      "Video, images, text\n",
      "\n",
      "Classification, action detection\n",
      "\n",
      "Activitynet\n",
      "\n",
      "Large video dataset for activity recognition and detection.\n",
      "\n",
      "Actions classified and labeled.\n",
      "\n",
      "10,024\n",
      "\n",
      "Video, images, text\n",
      "\n",
      "Classification, action detection\n",
      "\n",
      "MSP-AVATAR\n",
      "\n",
      "Improvised scenarios annotated for discourse functions: contrast, confirmation/negation, question, uncertainty, suggest, giving orders, warn, inform, size description, using pronouns.\n",
      "\n",
      "Actions classified and labeled.\n",
      "\n",
      "74 sessions\n",
      "\n",
      "Motion-captured video, audio\n",
      "\n",
      "Classification, action detection\n",
      "\n",
      "LILiR Twotalk Corpus\n",
      "\n",
      "Video datasets for non-verbal communication activity recognition: agreement, thinking, asking and understanding.\n",
      "\n",
      "Actions classified and labeled.\n",
      "\n",
      "527\n",
      "\n",
      "Video\n",
      "\n",
      "Action detection\n",
      "\n",
      "MEXAction2\n",
      "\n",
      "Video dataset for action localization and spotting\n",
      "\n",
      "Actions classified and labeled.\n",
      "\n",
      "1000\n",
      "\n",
      "Video\n",
      "\n",
      "Action detection\n",
      "\n",
      "Visual Genome\n",
      "\n",
      "Images and their description\n",
      "\n",
      "\n",
      "\n",
      "108,000\n",
      "\n",
      "images, text\n",
      "\n",
      "Image captioning\n",
      "\n",
      "DAVIS: Densely Annotated VIdeo Segmentation 2017\n",
      "\n",
      "150 video sequences containing 10459 frames with a total of 376 objects annotated.\n",
      "\n",
      "Dataset released for the 2017 DAVIS Challenge with a dedicated workshop co-located with CVPR 2017. The videos contain several types of objects and humans with a high quality segmentation annotation.In each video sequence multiple instances are annotated.\n",
      "\n",
      "10,459\n",
      "\n",
      "Frames annotated\n",
      "\n",
      "Video object segmentation\n",
      "\n",
      "DAVIS: Densely Annotated VIdeo Segmentation 2016\n",
      "\n",
      "50 video sequences containing 3455 frames with a total of 50 objects annotated.\n",
      "\n",
      "Dataset released with the CVPR 2016 paper. The videos contain several types of objects and humans with a high quality segmentation annotation. In each video sequence a single instance is annotated.\n",
      "\n",
      "3,455\n",
      "\n",
      "Frames annotated\n",
      "\n",
      "Video object segmentation\n",
      "\n",
      "T-LESS: An RGB-D Dataset for 6D Pose Estimation of Texture-less Objects\n",
      "\n",
      "30 industry-relevant objects. 39K training and 10K test images from each of three sensors. Two types of 3D models for each object.\n",
      "\n",
      "6D poses for all modeled objects in all images. Per-pixel labelling can be obtained by rendering of the object models at the ground truth poses.\n",
      "\n",
      "49,000\n",
      "\n",
      "RGB-D images, 3D object models\n",
      "\n",
      "6D object pose estimation, object detection\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berkeley 3-D Object Dataset\n",
      "\n",
      "849 images taken in 75 different scenes. About 50 different object classes are labeled.\n",
      "\n",
      "Object bounding boxes and labeling.\n",
      "\n",
      "849\n",
      "\n",
      "labeled images, text\n",
      "\n",
      "Object recognition\n",
      "\n",
      "Berkeley Segmentation Data Set and Benchmarks 500 (BSDS500)\n",
      "\n",
      "500 natural images, explicitly separated into disjoint train, validation and test subsets + benchmarking code. Based on BSDS300.\n",
      "\n",
      "Each image segmented by five different subjects on average.\n",
      "\n",
      "500\n",
      "\n",
      "Segmented images\n",
      "\n",
      "Contour detection and hierarchical image segmentation\n",
      "\n",
      "Microsoft Common Objects in Context (COCO)\n",
      "\n",
      "complex everyday scenes of common objects in their natural context.\n",
      "\n",
      "Object highlighting, labeling, and classification into 91 object types.\n",
      "\n",
      "2,500,000\n",
      "\n",
      "Labeled images, text\n",
      "\n",
      "Object recognition\n",
      "\n",
      "SUN Database\n",
      "\n",
      "Very large scene and object recognition database.\n",
      "\n",
      "Places and objects are labeled. Objects are segmented.\n",
      "\n",
      "131,067\n",
      "\n",
      "Images, text\n",
      "\n",
      "Object recognition, scene recognition\n",
      "\n",
      "ImageNet\n",
      "\n",
      "Labeled object image database, used in the ImageNet Large Scale Visual Recognition Challenge\n",
      "\n",
      "Labeled objects, bounding boxes, descriptive words, SIFT features\n",
      "\n",
      "14,197,122\n",
      "\n",
      "Images, text\n",
      "\n",
      "Object recognition, scene recognition\n",
      "\n",
      "Open Images\n",
      "\n",
      "A Large set of images listed as having CC BY 2.0 license with image-level labels and bounding boxes spanning thousands of classes.\n",
      "\n",
      "Image-level labels, Bounding boxes\n",
      "\n",
      "9,178,275\n",
      "\n",
      "Images, text\n",
      "\n",
      "Classification, Object recognition\n",
      "\n",
      "TV News Channel Commercial Detection Dataset\n",
      "\n",
      "TV commercials and news broadcasts.\n",
      "\n",
      "Audio and video features extracted from still images.\n",
      "\n",
      "129,685\n",
      "\n",
      "Text\n",
      "\n",
      "Clustering, classification\n",
      "\n",
      "Statlog (Image Segmentation) Dataset\n",
      "\n",
      "The instances were drawn randomly from a database of 7 outdoor images and hand-segmented to create a classification for every pixel.\n",
      "\n",
      "Many features calculated.\n",
      "\n",
      "2310\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Caltech 101\n",
      "\n",
      "Pictures of objects.\n",
      "\n",
      "Detailed object outlines marked.\n",
      "\n",
      "9146\n",
      "\n",
      "Images\n",
      "\n",
      "Classification, object recognition.\n",
      "\n",
      "Caltech-256\n",
      "\n",
      "Large dataset of images for object classification.\n",
      "\n",
      "Images categorized and hand-sorted.\n",
      "\n",
      "30,607\n",
      "\n",
      "Images, Text\n",
      "\n",
      "Classification, object detection\n",
      "\n",
      "SIFT10M Dataset\n",
      "\n",
      "SIFT features of Caltech-256 dataset.\n",
      "\n",
      "Extensive SIFT feature extraction.\n",
      "\n",
      "11,164,866\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, object detection\n",
      "\n",
      "LabelMe\n",
      "\n",
      "Annotated pictures of scenes.\n",
      "\n",
      "Objects outlined.\n",
      "\n",
      "187,240\n",
      "\n",
      "Images, text\n",
      "\n",
      "Classification, object detection\n",
      "\n",
      "Cityscapes Dataset\n",
      "\n",
      "Stereo video sequences recorded in street scenes, with pixel-level annotations. Metadata also included.\n",
      "\n",
      "Pixel-level segmentation and labeling\n",
      "\n",
      "25,000\n",
      "\n",
      "Images, text\n",
      "\n",
      "Classification, object detection\n",
      "\n",
      "PASCAL VOC Dataset\n",
      "\n",
      "Large number of images for classification tasks.\n",
      "\n",
      "Labeling, bounding box included\n",
      "\n",
      "500,000\n",
      "\n",
      "Images, text\n",
      "\n",
      "Classification, object detection\n",
      "\n",
      "CIFAR-10 Dataset\n",
      "\n",
      "Many small, low-resolution, images of 10 classes of objects.\n",
      "\n",
      "Classes labelled, training set splits created.\n",
      "\n",
      "60,000\n",
      "\n",
      "Images\n",
      "\n",
      "Classification\n",
      "\n",
      "CIFAR-100 Dataset\n",
      "\n",
      "Like CIFAR-10, above, but 100 classes of objects are given.\n",
      "\n",
      "Classes labelled, training set splits created.\n",
      "\n",
      "60,000\n",
      "\n",
      "Images\n",
      "\n",
      "Classification\n",
      "\n",
      "CINIC-10 Dataset\n",
      "\n",
      "A unified contribution of CIFAR-10 and Imagenet with 10 classes, and 3 splits. Larger than CIFAR-10.\n",
      "\n",
      "Classes labelled, training, validation, test set splits created.\n",
      "\n",
      "270,000\n",
      "\n",
      "Images\n",
      "\n",
      "Classification\n",
      "\n",
      "Fashion-MNIST\n",
      "\n",
      "A MNIST-like fashion product database\n",
      "\n",
      "Classes labelled, training set splits created.\n",
      "\n",
      "60,000\n",
      "\n",
      "Images\n",
      "\n",
      "Classification\n",
      "\n",
      "notMNIST\n",
      "\n",
      "Some publicly available fonts and extracted glyphs from them to make a dataset similar to MNIST. There are 10 classes, with letters A-J taken from different fonts.\n",
      "\n",
      "Classes labelled, training set splits created.\n",
      "\n",
      "500,000\n",
      "\n",
      "Images\n",
      "\n",
      "Classification\n",
      "\n",
      "German Traffic Sign Detection Benchmark Dataset\n",
      "\n",
      "Images from vehicles of traffic signs on German roads. These signs comply with UN standards and therefore are the same as in other countries.\n",
      "\n",
      "Signs manually labeled\n",
      "\n",
      "900\n",
      "\n",
      "Images\n",
      "\n",
      "Classification\n",
      "\n",
      "KITTI Vision Benchmark Dataset\n",
      "\n",
      "Autonomous vehicles driving through a mid-size city captured images of various areas using cameras and laser scanners.\n",
      "\n",
      "Many benchmarks extracted from data.\n",
      "\n",
      ">100 GB of data\n",
      "\n",
      "Images, text\n",
      "\n",
      "Classification, object detection\n",
      "\n",
      "Linnaeus 5 dataset\n",
      "\n",
      "Images of 5 classes of objects.\n",
      "\n",
      "Classes labelled, training set splits created.\n",
      "\n",
      "8000\n",
      "\n",
      "Images\n",
      "\n",
      "Classification\n",
      "\n",
      "FieldSAFE\n",
      "\n",
      "Multi-modal dataset for obstacle detection in agriculture including stereo camera, thermal camera, web camera, 360-degree camera, lidar, radar, and precise localization.\n",
      "\n",
      "Classes labelled geographically.\n",
      "\n",
      ">400 GB of data\n",
      "\n",
      "Images and 3D point clouds\n",
      "\n",
      "Classification, object detection, object localization\n",
      "\n",
      "11K Hands\n",
      "\n",
      "11,076 hand images (1600 x 1200 pixels) of 190 subjects, of varying ages between 18 â€“ 75 years old, for gender recognition and biometric identification.\n",
      "\n",
      "None\n",
      "\n",
      "11,076 hand images\n",
      "\n",
      "Images and (.mat, .txt, and .csv) label files\n",
      "\n",
      "Gender recognition and biometric identification\n",
      "\n",
      "CORe50\n",
      "\n",
      "Specifically designed for Continuous/Lifelong Learning and Object Recognition, is a collection of more than 500 videos (30fps) of 50 domestic objects belonging to 10 different categories.\n",
      "\n",
      "Classes labelled, training set splits created based on a 3-way, multi-runs benchmark.\n",
      "\n",
      "164,866 RBG-D images\n",
      "\n",
      "images (.png or .pkl)\n",
      "and (.pkl, .txt, .tsv) label files\n",
      "\n",
      "\n",
      "Classification, Object recognition\n",
      "\n",
      "Artificial Characters Dataset\n",
      "\n",
      "Artificially generated data describing the structure of 10 capital English letters.\n",
      "\n",
      "Coordinates of lines drawn given as integers. Various other features.\n",
      "\n",
      "6000\n",
      "\n",
      "Text\n",
      "\n",
      "Handwriting recognition, classification\n",
      "\n",
      "Letter Dataset\n",
      "\n",
      "Upper case printed letters.\n",
      "\n",
      "17 features are extracted from all images.\n",
      "\n",
      "20,000\n",
      "\n",
      "Text\n",
      "\n",
      "OCR, classification\n",
      "\n",
      "Character Trajectories Dataset\n",
      "\n",
      "Labeled samples of pen tip trajectories for people writing simple characters.\n",
      "\n",
      "3-dimensional pen tip velocity trajectory matrix for each sample\n",
      "\n",
      "2858\n",
      "\n",
      "Text\n",
      "\n",
      "Handwriting recognition, classification\n",
      "\n",
      "Chars74K Dataset\n",
      "\n",
      "Character recognition in natural images of symbols used in both English and Kannada\n",
      "\n",
      "\n",
      "\n",
      "74,107\n",
      "\n",
      "\n",
      "\n",
      "Character recognition, handwriting recognition, OCR, classification\n",
      "\n",
      "UJI Pen Characters Dataset\n",
      "\n",
      "Isolated handwritten characters\n",
      "\n",
      "Coordinates of pen position as characters were written given.\n",
      "\n",
      "11,640\n",
      "\n",
      "Text\n",
      "\n",
      "Handwriting recognition, classification\n",
      "\n",
      "Gisette Dataset\n",
      "\n",
      "Handwriting samples from the often-confused 4 and 9 characters.\n",
      "\n",
      "Features extracted from images, split into train/test, handwriting images size-normalized.\n",
      "\n",
      "13,500\n",
      "\n",
      "Images, text\n",
      "\n",
      "Handwriting recognition, classification\n",
      "\n",
      "MNIST database\n",
      "\n",
      "Database of handwritten digits.\n",
      "\n",
      "Hand-labeled.\n",
      "\n",
      "60,000\n",
      "\n",
      "Images, text\n",
      "\n",
      "Classification\n",
      "\n",
      "Optical Recognition of Handwritten Digits Dataset\n",
      "\n",
      "Normalized bitmaps of handwritten data.\n",
      "\n",
      "Size normalized and mapped to bitmaps.\n",
      "\n",
      "5620\n",
      "\n",
      "Images, text\n",
      "\n",
      "Handwriting recognition, classification\n",
      "\n",
      "Pen-Based Recognition of Handwritten Digits Dataset\n",
      "\n",
      "Handwritten digits on electronic pen-tablet.\n",
      "\n",
      "Feature vectors extracted to be uniformly spaced.\n",
      "\n",
      "10,992\n",
      "\n",
      "Images, text\n",
      "\n",
      "Handwriting recognition, classification\n",
      "\n",
      "Semeion Handwritten Digit Dataset\n",
      "\n",
      "Handwritten digits from 80 people.\n",
      "\n",
      "All handwritten digits have been normalized for size and mapped to the same grid.\n",
      "\n",
      "1593\n",
      "\n",
      "Images, text\n",
      "\n",
      "Handwriting recognition, classification\n",
      "\n",
      "HASYv2\n",
      "\n",
      "Handwritten mathematical symbols\n",
      "\n",
      "All symbols are centered and of size 32px x 32px.\n",
      "\n",
      "168233\n",
      "\n",
      "Images, text\n",
      "\n",
      "Classification\n",
      "\n",
      "Noisy Handwritten Bangla Dataset\n",
      "\n",
      "Includes Handwritten Numeral Dataset (10 classes) and Basic Character Dataset (50 classes), each dataset has three types of noise: white gaussian, motion blur, and reduced contrast.\n",
      "\n",
      "All images are centered and of size 32x32.\n",
      "\n",
      "Numeral Dataset:\n",
      "23330,\n",
      "Character Dataset:\n",
      "76000\n",
      "\n",
      "\n",
      "Images,\n",
      "text\n",
      "\n",
      "\n",
      "Handwriting recognition,\n",
      "classification\n",
      "\n",
      "\n",
      "Aerial Image Segmentation Dataset\n",
      "\n",
      "80 high-resolution aerial images with spatial resolution ranging from 0.3 to 1.0.\n",
      "\n",
      "Images manually segmented.\n",
      "\n",
      "80\n",
      "\n",
      "Images\n",
      "\n",
      "Aerial Classification, object detection\n",
      "\n",
      "KIT AIS Data Set\n",
      "\n",
      "Multiple labeled training and evaluation datasets of aerial images of crowds.\n",
      "\n",
      "Images manually labeled to show paths of individuals through crowds.\n",
      "\n",
      "~ 150\n",
      "\n",
      "Images with paths\n",
      "\n",
      "People tracking, aerial tracking\n",
      "\n",
      "Wilt Dataset\n",
      "\n",
      "Remote sensing data of diseased trees and other land cover.\n",
      "\n",
      "Various features extracted.\n",
      "\n",
      "4899\n",
      "\n",
      "Images\n",
      "\n",
      "Classification, aerial object detection\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Type Mapping Dataset\n",
      "\n",
      "Satellite imagery of forests in Japan.\n",
      "\n",
      "Image wavelength bands extracted.\n",
      "\n",
      "326\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Overhead Imagery Research Data Set\n",
      "\n",
      "Annotated overhead imagery. Images with multiple objects.\n",
      "\n",
      "Over 30 annotations and over 60 statistics that describe the target within the context of the image.\n",
      "\n",
      "1000\n",
      "\n",
      "Images, text\n",
      "\n",
      "Classification\n",
      "\n",
      "SpaceNet\n",
      "\n",
      "SpaceNet is a corpus of commercial satellite imagery and labeled training data.\n",
      "\n",
      "GeoTiff and GeoJSON files containing building footprints.\n",
      "\n",
      ">17533\n",
      "\n",
      "Images\n",
      "\n",
      "Classification, Object Identification\n",
      "\n",
      "UC Merced Land Use Dataset\n",
      "\n",
      "These images were manually extracted from large images from the USGS National Map Urban Area Imagery collection for various urban areas around the US.\n",
      "\n",
      "This is a 21 class land use image dataset meant for research purposes. There are 100 images for each  class.\n",
      "\n",
      "2,100\n",
      "\n",
      "Image chips of 256x256, 30Â cm (1 foot) GSD\n",
      "\n",
      "Land cover classification\n",
      "\n",
      "SAT-4 Airborne Dataset\n",
      "\n",
      "Images were extracted from the National Agriculture Imagery Program (NAIP) dataset.\n",
      "\n",
      "SAT-4 has four broad land cover classes, includes barren land, trees, grassland and a class that consists of all land cover classes other than the above three.\n",
      "\n",
      "500,000\n",
      "\n",
      "Images\n",
      "\n",
      "Classification\n",
      "\n",
      "SAT-6 Airborne Dataset\n",
      "\n",
      "Images were extracted from the National Agriculture Imagery Program (NAIP) dataset.\n",
      "\n",
      "SAT-6 has six broad land cover classes, includes barren land, trees, grassland, roads, buildings and water bodies.\n",
      "\n",
      "405,000\n",
      "\n",
      "Images\n",
      "\n",
      "Classification\n",
      "\n",
      "Quantum simulations of an electron in a two dimensional potential well\n",
      "\n",
      "Labelled images of raw input to a simulation of 2d Quantum mechanics\n",
      "\n",
      "Raw data (in HDF5 format) and output labels from quantum simulation\n",
      "\n",
      "1.3 million images\n",
      "\n",
      "Labeled images\n",
      "\n",
      "Regression\n",
      "\n",
      "MPII Cooking Activities Dataset\n",
      "\n",
      "Videos and images of various cooking activities.\n",
      "\n",
      "Activity paths and directions, labels, fine-grained motion labeling, activity class, still image extraction and labeling.\n",
      "\n",
      "881,755 frames\n",
      "\n",
      "Labeled video, images, text\n",
      "\n",
      "Classification\n",
      "\n",
      "FAMOS Dataset\n",
      "\n",
      "5,000 unique microstructures, all samples have been acquired 3 times with two different cameras.\n",
      "\n",
      "Original PNG files, sorted per camera and then per acquisition. MATLAB datafiles with one 16384 times 5000 matrix per camera per acquisition.\n",
      "\n",
      "30,000\n",
      "\n",
      "Images and .mat files\n",
      "\n",
      "Authentication\n",
      "\n",
      "PharmaPack Dataset\n",
      "\n",
      "1,000 unique classes with 54 images per class.\n",
      "\n",
      "Class labeling, many local descriptors, like SIFT and aKaZE, and local feature agreators, like Fisher Vector (FV).\n",
      "\n",
      "54,000\n",
      "\n",
      "Images and .mat files\n",
      "\n",
      "Fine-grain classification\n",
      "\n",
      "Stanford Dogs Dataset\n",
      "\n",
      "Images of 120 breeds of dogs from around the world.\n",
      "\n",
      "Train/test splits and ImageNet annotations provided.\n",
      "\n",
      "20,580\n",
      "\n",
      "Images, text\n",
      "\n",
      "Fine-grain classification\n",
      "\n",
      "The Oxford-IIIT Pet Dataset\n",
      "\n",
      "37 categories of pets with roughly 200 images of each.\n",
      "\n",
      "Breed labeled, tight bounding box, foreground-background segmentation.\n",
      "\n",
      "~ 7,400\n",
      "\n",
      "Images, text\n",
      "\n",
      "Classification, object detection\n",
      "\n",
      "Corel Image Features Data Set\n",
      "\n",
      "Database of images with features extracted.\n",
      "\n",
      "Many features including color histogram, co-occurrence texture, and colormoments,\n",
      "\n",
      "68,040\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, object detection\n",
      "\n",
      "Online Video Characteristics and Transcoding Time Dataset.\n",
      "\n",
      "Transcoding times for various different videos and video properties.\n",
      "\n",
      "Video features given.\n",
      "\n",
      "168,286\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "Microsoft Sequential Image Narrative Dataset (SIND)\n",
      "\n",
      "Dataset for sequential vision-to-language\n",
      "\n",
      "Descriptive caption and storytelling given for each photo, and photos are arranged in sequences\n",
      "\n",
      "81,743\n",
      "\n",
      "Images, text\n",
      "\n",
      "Visual storytelling\n",
      "\n",
      "Caltech-UCSD Birds-200-2011 Dataset\n",
      "\n",
      "Large dataset of images of birds.\n",
      "\n",
      "Part locations for birds, bounding boxes, 312 binary attributes given\n",
      "\n",
      "11,788\n",
      "\n",
      "Images, text\n",
      "\n",
      "Classification\n",
      "\n",
      "YouTube-8M\n",
      "\n",
      "Large and diverse labeled video dataset\n",
      "\n",
      "YouTube video IDs and associated labels from a diverse vocabulary of 4800 visual entities\n",
      "\n",
      "8 million\n",
      "\n",
      "Video, text\n",
      "\n",
      "Video classification\n",
      "\n",
      "YFCC100M\n",
      "\n",
      "Large and diverse labeled image and video dataset\n",
      "\n",
      "Flickr Videos and Images and associated description, titles, tags, and other metadata (such as EXIF and geotags)\n",
      "\n",
      "100Â million\n",
      "\n",
      "Video, Image, Text\n",
      "\n",
      "Video and Image classification\n",
      "\n",
      "Discrete LIRIS-ACCEDE\n",
      "\n",
      "Short videos annotated for valence and arousal.\n",
      "\n",
      "Valence and arousal labels.\n",
      "\n",
      "9800\n",
      "\n",
      "Video\n",
      "\n",
      "Video emotion elicitation detection\n",
      "\n",
      "Continuous LIRIS-ACCEDE\n",
      "\n",
      "Long videos annotated for valence and arousal while also collecting Galvanic Skin Response.\n",
      "\n",
      "Valence and arousal labels.\n",
      "\n",
      "30\n",
      "\n",
      "Video\n",
      "\n",
      "Video emotion elicitation detection\n",
      "\n",
      "MediaEval LIRIS-ACCEDE\n",
      "\n",
      "Extension of Discrete LIRIS-ACCEDE including annotations for violence levels of the films.\n",
      "\n",
      "Violence, valence and arousal labels.\n",
      "\n",
      "10900\n",
      "\n",
      "Video\n",
      "\n",
      "Video emotion elicitation detection\n",
      "\n",
      "Leeds Sports Pose\n",
      "\n",
      "Articulated human pose annotations in 2000 natural sports images from Flickr.\n",
      "\n",
      "Rough crop around single person of interest with 14 joint labels\n",
      "\n",
      "2000\n",
      "\n",
      "Images plus .mat file labels\n",
      "\n",
      "Human pose estimation\n",
      "\n",
      "Leeds Sports Pose Extended Training\n",
      "\n",
      "Articulated human pose annotations in 10,000 natural sports images from Flickr.\n",
      "\n",
      "14 joint labels via crowdsourcing\n",
      "\n",
      "10000\n",
      "\n",
      "Images plus .mat file labels\n",
      "\n",
      "Human pose estimation\n",
      "\n",
      "MCQ Dataset\n",
      "\n",
      "6 different real multiple choice-based exams (735 answer sheets and 33,540 answer boxes) to evaluate computer vision techniques and systems developed for multiple choice test assessment systems.\n",
      "\n",
      "None\n",
      "\n",
      "735 answer sheets and 33,540 answer boxes\n",
      "\n",
      "Images and .mat file labels\n",
      "\n",
      "Development of multiple choice test assessment systems\n",
      "\n",
      "Surveillance Videos\n",
      "\n",
      "Real surveillance videos cover a large surveillance time (7 days with 24 hours each).\n",
      "\n",
      "None\n",
      "\n",
      "19 surveillance videos (7 days with 24 hours each).\n",
      "\n",
      "Videos\n",
      "\n",
      "Data compression\n",
      "\n",
      "LILA BC\n",
      "\n",
      "Labeled Information Library of Alexandria: Biology and Conservation.  Labeled images that support machine learning research around ecology and environmental science.\n",
      "\n",
      "None\n",
      "\n",
      "~10M images\n",
      "\n",
      "Images\n",
      "\n",
      "Classification\n",
      "\n",
      "Can We See Photosynthesis?\n",
      "\n",
      "32 videos for eight live and eight dead leaves recorded under both DC and AC lighting conditions.\n",
      "\n",
      "None\n",
      "\n",
      "32 videos\n",
      "\n",
      "Videos\n",
      "\n",
      "Liveness detection of plants\n",
      "\n",
      "Amazon reviews\n",
      "\n",
      "US product reviews from Amazon.com.\n",
      "\n",
      "None.\n",
      "\n",
      "~ 82M\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, sentiment analysis\n",
      "\n",
      "OpinRank Review Dataset\n",
      "\n",
      "Reviews of cars and hotels from Edmunds.com and TripAdvisor respectively.\n",
      "\n",
      "None.\n",
      "\n",
      "42,230 / ~259,000 respectively\n",
      "\n",
      "Text\n",
      "\n",
      "Sentiment analysis, clustering\n",
      "\n",
      "MovieLens\n",
      "\n",
      "22,000,000 ratings and 580,000 tags applied to 33,000 movies by 240,000 users.\n",
      "\n",
      "None.\n",
      "\n",
      "~ 22M\n",
      "\n",
      "Text\n",
      "\n",
      "Regression, clustering, classification\n",
      "\n",
      "Yahoo! Music User Ratings of Musical Artists\n",
      "\n",
      "Over 10M ratings of artists by Yahoo users.\n",
      "\n",
      "None described.\n",
      "\n",
      "~ 10M\n",
      "\n",
      "Text\n",
      "\n",
      "Clustering, regression\n",
      "\n",
      "Car Evaluation Data Set\n",
      "\n",
      "Car properties and their overall acceptability.\n",
      "\n",
      "Six categorical features given.\n",
      "\n",
      "1728\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "YouTube Comedy Slam Preference Dataset\n",
      "\n",
      "User vote data for pairs of videos shown on YouTube. Users voted on funnier videos.\n",
      "\n",
      "Video metadata given.\n",
      "\n",
      "1,138,562\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Skytrax User Reviews Dataset\n",
      "\n",
      "User reviews of airlines, airports, seats, and lounges from Skytrax.\n",
      "\n",
      "Ratings are fine-grain and include many aspects of airport experience.\n",
      "\n",
      "41396\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, regression\n",
      "\n",
      "Teaching Assistant Evaluation Dataset\n",
      "\n",
      "Teaching assistant reviews.\n",
      "\n",
      "Features of each instance such as class, class size, and instructor are given.\n",
      "\n",
      "151\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "NYSK Dataset\n",
      "\n",
      "English news articles about the case relating to allegations of sexual assault against the former IMF director Dominique Strauss-Kahn.\n",
      "\n",
      "Filtered and presented in XML format.\n",
      "\n",
      "10,421\n",
      "\n",
      "XML, text\n",
      "\n",
      "Sentiment analysis, topic extraction\n",
      "\n",
      "The Reuters Corpus Volume 1\n",
      "\n",
      "Large corpus of Reuters news stories in English.\n",
      "\n",
      "Fine-grain categorization and topic codes.\n",
      "\n",
      "810,000\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering, summarization\n",
      "\n",
      "The Reuters Corpus Volume 2\n",
      "\n",
      "Large corpus of Reuters news stories in multiple languages.\n",
      "\n",
      "Fine-grain categorization and topic codes.\n",
      "\n",
      "487,000\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering, summarization\n",
      "\n",
      "Thomson Reuters Text Research Collection\n",
      "\n",
      "Large corpus of news stories.\n",
      "\n",
      "Details not described.\n",
      "\n",
      "1,800,370\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering, summarization\n",
      "\n",
      "Saudi Newspapers Corpus\n",
      "\n",
      "31,030 Arabic newspaper articles.\n",
      "\n",
      "Metadata extracted.\n",
      "\n",
      "31,030\n",
      "\n",
      "JSON\n",
      "\n",
      "Summarization, clustering\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RE3D (Relationship and Entity Extraction Evaluation Dataset)\n",
      "\n",
      "Entity and Relation marked data from various news and government sources. Sponsored by Dstl\n",
      "\n",
      "Filtered, categorisation using Baleen types\n",
      "\n",
      "not known\n",
      "\n",
      "JSON\n",
      "\n",
      "Classification, Entity and Relation recognition\n",
      "\n",
      "ABC Australia News Corpus\n",
      "\n",
      "Entire news corpus of ABC Australia from 2003 to 2017\n",
      "\n",
      "Publish date and headlines\n",
      "\n",
      "1,082,477\n",
      "\n",
      "CSV\n",
      "\n",
      "Clustering, Events, Sentiment\n",
      "\n",
      "Examiner Pseudo-News Corpus\n",
      "\n",
      "Clickbait, spam, crowd-sourced headlines from 2010 to 2015\n",
      "\n",
      "Publish date and headlines\n",
      "\n",
      "3,089,781\n",
      "\n",
      "CSV\n",
      "\n",
      "Clustering, Events, Sentiment\n",
      "\n",
      "Worldwide News - Aggregate of 20K Feeds\n",
      "\n",
      "One week snapshot of all online headlines in 20+ languages\n",
      "\n",
      "Publish time, URL and headlines\n",
      "\n",
      "1,398,431\n",
      "\n",
      "CSV\n",
      "\n",
      "Clustering, Events, Language Detection\n",
      "\n",
      "Reuters News Wire Headline\n",
      "\n",
      "11+ Years of timestamped events published on the news-wire\n",
      "\n",
      "Publish time, Headline Text\n",
      "\n",
      "16,121,000\n",
      "\n",
      "CSV\n",
      "\n",
      "NLP, Computational Linguistics, Events\n",
      "\n",
      "The Irish Times The Irish Times IRS\n",
      "\n",
      "12 Years of Events From Ireland\n",
      "\n",
      "Publish time, Headline Text\n",
      "\n",
      "1,422,000\n",
      "\n",
      "CSV\n",
      "\n",
      "NLP, Computational Linguistics, Events\n",
      "\n",
      "News Headlines Dataset for Sarcasm Detection\n",
      "\n",
      "High quality dataset with Sarcastic and Non-sarcastic news headlines.\n",
      "\n",
      "Clean, normalized text\n",
      "\n",
      "26709\n",
      "\n",
      "JSON\n",
      "\n",
      "NLP, Classification, Linguistics\n",
      "\n",
      "Enron Email Dataset\n",
      "\n",
      "Emails from employees at Enron organized into folders.\n",
      "\n",
      "Attachments removed, invalid email addresses converted to user@enron.com or no_address@enron.com.\n",
      "\n",
      "~ 500,000\n",
      "\n",
      "Text\n",
      "\n",
      "Network analysis, sentiment analysis\n",
      "\n",
      "Ling-Spam Dataset\n",
      "\n",
      "Corpus containing both legitimate and spam emails.\n",
      "\n",
      "Four version of the corpus involving whether or not a lemmatiser or stop-list was enabled.\n",
      "\n",
      "\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "SMS Spam Collection Dataset\n",
      "\n",
      "Collected SMS spam messages.\n",
      "\n",
      "None.\n",
      "\n",
      "5574\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Twenty Newsgroups Dataset\n",
      "\n",
      "Messages from 20 different newsgroups.\n",
      "\n",
      "None.\n",
      "\n",
      "20,000\n",
      "\n",
      "Text\n",
      "\n",
      "Natural language processing\n",
      "\n",
      "Spambase Dataset\n",
      "\n",
      "Spam emails.\n",
      "\n",
      "Many text features extracted.\n",
      "\n",
      "4601\n",
      "\n",
      "Text\n",
      "\n",
      "Spam detection, classification\n",
      "\n",
      "MovieTweetings\n",
      "\n",
      "Movie rating dataset  based on public and well-structured tweets\n",
      "\n",
      "\n",
      "\n",
      "~710,000\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, regression\n",
      "\n",
      "Twitter100k\n",
      "\n",
      "Pairs of images and tweets\n",
      "\n",
      "\n",
      "\n",
      "100,000\n",
      "\n",
      "Text and Images\n",
      "\n",
      "Cross-media retrieval\n",
      "\n",
      "Sentiment140\n",
      "\n",
      "Tweet data from 2009 including original text, time stamp, user and sentiment.\n",
      "\n",
      "Classified using distant supervision from presence of emoticon in tweet.\n",
      "\n",
      "1,578,627\n",
      "\n",
      "Tweets, comma, separated values\n",
      "\n",
      "Sentiment analysis\n",
      "\n",
      "ASU Twitter Dataset\n",
      "\n",
      "Twitter network data, not actual tweets. Shows connections between a large number of users.\n",
      "\n",
      "None.\n",
      "\n",
      "11,316,811 users, 85,331,846 connections\n",
      "\n",
      "Text\n",
      "\n",
      "Clustering, graph analysis\n",
      "\n",
      "SNAP Social Circles: Twitter Database\n",
      "\n",
      "Large Twitter network data.\n",
      "\n",
      "Node features, circles, and ego networks.\n",
      "\n",
      "1,768,149\n",
      "\n",
      "Text\n",
      "\n",
      "Clustering, graph analysis\n",
      "\n",
      "Twitter Dataset for Arabic Sentiment Analysis\n",
      "\n",
      "Arabic tweets.\n",
      "\n",
      "Samples hand-labeled as positive or negative.\n",
      "\n",
      "2000\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Buzz in Social Media Dataset\n",
      "\n",
      "Data from Twitter and Tom's Hardware. This dataset focuses on specific buzz topics being discussed on those sites.\n",
      "\n",
      "Data is windowed so that the user can attempt to predict the events leading up to social media buzz.\n",
      "\n",
      "140,000\n",
      "\n",
      "Text\n",
      "\n",
      "Regression, Classification\n",
      "\n",
      "Paraphrase and Semantic Similarity in Twitter (PIT)\n",
      "\n",
      "This dataset focuses on whether tweets have (almost) same meaning/information or not. Manually labeled.\n",
      "\n",
      "tokenization, part-of-speech and named entity tagging\n",
      "\n",
      "18,762\n",
      "\n",
      "Text\n",
      "\n",
      "Regression, Classification\n",
      "\n",
      "Geoparse Twitter benchmark dataset\n",
      "\n",
      "This dataset contains tweets during different news events in different countries. Manually labeled location mentions.\n",
      "\n",
      "location annotations added to JSON metadata\n",
      "\n",
      "6,386\n",
      "\n",
      "Tweets, JSON\n",
      "\n",
      "Classification, Information Extraction\n",
      "\n",
      "NPS Chat Corpus\n",
      "\n",
      "Posts from age-specific online chat rooms.\n",
      "\n",
      "Hand privacy masked, tagged for part of speech and dialogue-act.\n",
      "\n",
      "~ 500,000\n",
      "\n",
      "XML\n",
      "\n",
      "NLP, programming, linguistics\n",
      "\n",
      "Twitter Triple Corpus\n",
      "\n",
      "A-B-A triples extracted from Twitter.\n",
      "\n",
      "\n",
      "\n",
      "4,232\n",
      "\n",
      "Text\n",
      "\n",
      "NLP\n",
      "\n",
      "UseNet Corpus\n",
      "\n",
      "UseNet forum postings.\n",
      "\n",
      "Anonymized e-mails and URLs. Omitted documents with lengths <500 words or >500,000 words, or that were <90% English.\n",
      "\n",
      "7 billion\n",
      "\n",
      "Text\n",
      "\n",
      "\n",
      "\n",
      "NUS SMS Corpus\n",
      "\n",
      "SMS messages collected between two users, with timing analysis.\n",
      "\n",
      "\n",
      "\n",
      "~ 10,000\n",
      "\n",
      "XML\n",
      "\n",
      "NLP\n",
      "\n",
      "Reddit All Comments Corpus\n",
      "\n",
      "All Reddit comments (as of 2015).\n",
      "\n",
      "\n",
      "\n",
      "~ 1.7 billion\n",
      "\n",
      "JSON\n",
      "\n",
      "NLP, research\n",
      "\n",
      "Ubuntu Dialogue Corpus\n",
      "\n",
      "Dialogues extracted from Ubuntu chat stream on IRC.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CSV\n",
      "\n",
      "Dialogue Systems Research\n",
      "\n",
      "Web of Science Dataset\n",
      "\n",
      "Hierarchical Datasets for Text Classification\n",
      "\n",
      "None.\n",
      "\n",
      "46,985\n",
      "\n",
      "Text\n",
      "\n",
      "Classification,\n",
      "Categorization\n",
      "\n",
      "\n",
      "Legal Case Reports\n",
      "\n",
      "Federal Court of Australia cases from 2006 to 2009.\n",
      "\n",
      "None.\n",
      "\n",
      "4,000\n",
      "\n",
      "Text\n",
      "\n",
      "Summarization,\n",
      "citation analysis\n",
      "\n",
      "\n",
      "Blogger Authorship Corpus\n",
      "\n",
      "Blog entries of 19,320 people from blogger.com.\n",
      "\n",
      "Blogger self-provided gender, age, industry, and astrological sign.\n",
      "\n",
      "681,288\n",
      "\n",
      "Text\n",
      "\n",
      "Sentiment analysis, summarization, classification\n",
      "\n",
      "Social Structure of Facebook Networks\n",
      "\n",
      "Large dataset of the social structure of Facebook.\n",
      "\n",
      "None.\n",
      "\n",
      "100 colleges covered\n",
      "\n",
      "Text\n",
      "\n",
      "Network analysis, clustering\n",
      "\n",
      "Dataset for the Machine Comprehension of Text\n",
      "\n",
      "Stories and associated questions for testing comprehension of text.\n",
      "\n",
      "None.\n",
      "\n",
      "660\n",
      "\n",
      "Text\n",
      "\n",
      "Natural language processing, machine comprehension\n",
      "\n",
      "The Penn Treebank Project\n",
      "\n",
      "Naturally occurring text annotated for linguistic structure.\n",
      "\n",
      "Text is parsed into semantic trees.\n",
      "\n",
      "~ 1M words\n",
      "\n",
      "Text\n",
      "\n",
      "Natural language processing, summarization\n",
      "\n",
      "DEXTER Dataset\n",
      "\n",
      "Task given is to determine, from features given, which articles are about corporate acquisitions.\n",
      "\n",
      "Features extracted include word stems. Distractor features included.\n",
      "\n",
      "2600\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Google Books N-grams\n",
      "\n",
      "N-grams from a very large corpus of books\n",
      "\n",
      "None.\n",
      "\n",
      "2.2 TB of text\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering, regression\n",
      "\n",
      "Personae Corpus\n",
      "\n",
      "Collected for experiments in Authorship Attribution and Personality Prediction. Consists of 145 Dutch-language essays.\n",
      "\n",
      "In addition to normal texts, syntactically annotated texts are given.\n",
      "\n",
      "145\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, regression\n",
      "\n",
      "CNAE-9 Dataset\n",
      "\n",
      "Categorization task for free text descriptions of Brazilian companies.\n",
      "\n",
      "Word frequency has been extracted.\n",
      "\n",
      "1080\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Sentiment Labeled Sentences Dataset\n",
      "\n",
      "3000 sentiment labeled sentences.\n",
      "\n",
      "Sentiment of each sentence has been hand labeled as positive or negative.\n",
      "\n",
      "3000\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, sentiment analysis\n",
      "\n",
      "BlogFeedback Dataset\n",
      "\n",
      "Dataset to predict the number of comments a post will receive based on features of that post.\n",
      "\n",
      "Many features of each post extracted.\n",
      "\n",
      "60,021\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "Stanford Natural Language Inference (SNLI) Corpus\n",
      "\n",
      "Image captions matched with newly constructed sentences to form entailment, contradiction, or neutral pairs.\n",
      "\n",
      "Entailment class labels, syntactic parsing by the Stanford PCFG parser\n",
      "\n",
      "570,000\n",
      "\n",
      "Text\n",
      "\n",
      "Natural language inference/recognizing textual entailment\n",
      "\n",
      "DSL Corpus Collection (DSLCC)\n",
      "\n",
      "A multilingual collection of short excerpts of journalistic texts in similar languages and dialects.\n",
      "\n",
      "None\n",
      "\n",
      "294,000 phrases\n",
      "\n",
      "Text\n",
      "\n",
      "Discriminating between similar languages\n",
      "\n",
      "Urban Dictionary Dataset\n",
      "\n",
      "Corpus of words, votes and definitions\n",
      "\n",
      "User names anonymised\n",
      "\n",
      "2,606,522\n",
      "\n",
      "CSV\n",
      "\n",
      "NLP, Machine comprehension\n",
      "\n",
      "T-REx\n",
      "\n",
      "Wikipedia abstracts aligned with Wikidata entities\n",
      "\n",
      "Alignment of Wikidata triples with Wikipedia abstracts\n",
      "\n",
      "11M aligned triples\n",
      "\n",
      "JSON and NIF [1]\n",
      "\n",
      "NLP, Relation Extraction\n",
      "\n",
      "Zero Resource Speech Challenge 2015\n",
      "\n",
      "Spontaneous speech (English), Read speech (Xitsonga).\n",
      "\n",
      "raw wav\n",
      "\n",
      "English: 5h, 12 speakers; Xitsonga: 2h30; 24 speakers\n",
      "\n",
      "sound\n",
      "\n",
      "Unsupervised discovery of speech features/subword units/word units\n",
      "\n",
      "Parkinson Speech Dataset\n",
      "\n",
      "Multiple recordings of people with and without Parkinson's Disease.\n",
      "\n",
      "Voice features extracted, disease scored by physician using unified Parkinson's disease rating scale\n",
      "\n",
      "1,040\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, regression\n",
      "\n",
      "Spoken Arabic Digits\n",
      "\n",
      "Spoken Arabic digits from 44 male and 44 female.\n",
      "\n",
      "Time-series of mel-frequency cepstrum coefficients.\n",
      "\n",
      "8,800\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "ISOLET Dataset\n",
      "\n",
      "Spoken letter names.\n",
      "\n",
      "Features extracted from sounds.\n",
      "\n",
      "7797\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Japanese Vowels Dataset\n",
      "\n",
      "Nine male speakers uttered two Japanese vowels successively.\n",
      "\n",
      "Applied 12-degree linear prediction analysis to it to obtain a discrete-time series with 12 cepstrum coefficients.\n",
      "\n",
      "640\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parkinson's Telemonitoring Dataset\n",
      "\n",
      "Multiple recordings of people with and without Parkinson's Disease.\n",
      "\n",
      "Sound features extracted.\n",
      "\n",
      "5875\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "TIMIT\n",
      "\n",
      "Recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences.\n",
      "\n",
      "Speech is lexically and phonemically transcribed.\n",
      "\n",
      "6300\n",
      "\n",
      "Text\n",
      "\n",
      "Speech recognition, classification.\n",
      "\n",
      "Arabic Speech Corpus\n",
      "\n",
      "A single-speaker, Modern Standard Arabic (MSA) speech corpus with phonetic and orthographic transcripts aligned to phoneme level\n",
      "\n",
      "Speech is orthographically and phonetically transcribed with stress marks.\n",
      "\n",
      "~1900\n",
      "\n",
      "Text, WAV\n",
      "\n",
      "Speech Synthesis, Speech Recognition, Corpus Alignment, Speech Therapy, Education.\n",
      "\n",
      "Geographical Original of Music Data Set\n",
      "\n",
      "Audio features of music samples from different locations.\n",
      "\n",
      "Audio features extracted using MARSYAS software.\n",
      "\n",
      "1,059\n",
      "\n",
      "Text\n",
      "\n",
      "Geographical classification, clustering\n",
      "\n",
      "Million Song Dataset\n",
      "\n",
      "Audio features from one million different songs.\n",
      "\n",
      "Audio features extracted.\n",
      "\n",
      "1M\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering\n",
      "\n",
      "Free Music Archive\n",
      "\n",
      "Audio under Creative Commons from 100k songs (343 days, 1TiB) with a hierarchy of 161 genres, metadata, user data, free-form text.\n",
      "\n",
      "Raw audio and audio features.\n",
      "\n",
      "106,574\n",
      "\n",
      "Text, MP3\n",
      "\n",
      "Classification, recommendation\n",
      "\n",
      "Bach Choral Harmony Dataset\n",
      "\n",
      "Bach chorale chords.\n",
      "\n",
      "Audio features extracted.\n",
      "\n",
      "5665\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "UrbanSound\n",
      "\n",
      "Labeled sound recordings of sounds like air conditioners, car horns and children playing.\n",
      "\n",
      "Sorted into folders by class of events as well as metadata in a JSON file and annotations in a CSV file.\n",
      "\n",
      "1,059\n",
      "\n",
      "Sound\n",
      "(WAV)\n",
      "\n",
      "\n",
      "Classification\n",
      "\n",
      "AudioSet\n",
      "\n",
      "10-second sound snippets from YouTube videos, and an ontology of over 500 labels.\n",
      "\n",
      "128-d PCA'd VGG-ish features every 1 second.\n",
      "\n",
      "2,084,320\n",
      "\n",
      "Text (CSV) and TensorFlow Record files\n",
      "\n",
      "Classification\n",
      "\n",
      "Bird Audio Detection challenge\n",
      "\n",
      "Audio from environmental monitoring stations, plus crowdsourced recordings\n",
      "\n",
      "\n",
      "\n",
      "17,000+\n",
      "\n",
      "\n",
      "\n",
      "Classification\n",
      "\n",
      "Witty Worm Dataset\n",
      "\n",
      "Dataset detailing the spread of the Witty worm and the infected computers.\n",
      "\n",
      "Split into a publicly available set and a restricted set containing more sensitive information like IP and UDP headers.\n",
      "\n",
      "55,909 IP addresses\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Cuff-Less Blood Pressure Estimation Dataset\n",
      "\n",
      "Cleaned vital signals from human patients which can be used to estimate blood pressure.\n",
      "\n",
      "125Â Hz vital signs have been cleaned.\n",
      "\n",
      "12,000\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, regression\n",
      "\n",
      "Gas Sensor Array Drift Dataset\n",
      "\n",
      "Measurements from 16 chemical sensors utilized in simulations for drift compensation.\n",
      "\n",
      "Extensive number of features given.\n",
      "\n",
      "13,910\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Servo Dataset\n",
      "\n",
      "Data covering the nonlinear relationships observed in a servo-amplifier circuit.\n",
      "\n",
      "Levels of various components as a function of other components are given.\n",
      "\n",
      "167\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "UJIIndoorLoc-Mag Dataset\n",
      "\n",
      "Indoor localization database to test indoor positioning systems. Data is magnetic field based.\n",
      "\n",
      "Train and test splits given.\n",
      "\n",
      "40,000\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, regression, clustering\n",
      "\n",
      "Sensorless Drive Diagnosis Dataset\n",
      "\n",
      "Electrical signals from motors with defective components.\n",
      "\n",
      "Statistical features extracted.\n",
      "\n",
      "58,508\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)\n",
      "\n",
      "People performing five standard actions while wearing motion tackers.\n",
      "\n",
      "None.\n",
      "\n",
      "165,632\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Gesture Phase Segmentation Dataset\n",
      "\n",
      "Features extracted from video of people doing various gestures.\n",
      "\n",
      "Features extracted aim at studying gesture phase segmentation.\n",
      "\n",
      "9900\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering\n",
      "\n",
      "Vicon Physical Action Data Set Dataset\n",
      "\n",
      "10 normal and 10 aggressive physical actions that measure the human activity tracked by a 3D tracker.\n",
      "\n",
      "Many parameters recorded by 3D tracker.\n",
      "\n",
      "3000\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Daily and Sports Activities Dataset\n",
      "\n",
      "Motor sensor data for 19 daily and sports activities.\n",
      "\n",
      "Many sensors given, no preprocessing done on signals.\n",
      "\n",
      "9120\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Human Activity Recognition Using Smartphones Dataset\n",
      "\n",
      "Gyroscope and accelerometer data from people wearing smartphones and performing normal actions.\n",
      "\n",
      "Actions performed are labeled, all signals preprocessed for noise.\n",
      "\n",
      "10,299\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Australian Sign Language Signs\n",
      "\n",
      "Australian sign language signs captured by motion-tracking gloves.\n",
      "\n",
      "None.\n",
      "\n",
      "2565\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Weight Lifting Exercises monitored with Inertial Measurement Units\n",
      "\n",
      "Five variations of the biceps curl exercise monitored with IMUs.\n",
      "\n",
      "Some statistics calculated from raw data.\n",
      "\n",
      "39,242\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "sEMG for Basic Hand movements Dataset\n",
      "\n",
      "Two databases of surface electromyographic signals of 6 hand movements.\n",
      "\n",
      "None.\n",
      "\n",
      "3000\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "REALDISP Activity Recognition Dataset\n",
      "\n",
      "Evaluate techniques dealing with the effects of sensor displacement in wearable activity recognition.\n",
      "\n",
      "None.\n",
      "\n",
      "1419\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Heterogeneity Activity Recognition Dataset\n",
      "\n",
      "Data from multiple different smart devices for humans performing various activities.\n",
      "\n",
      "None.\n",
      "\n",
      "43,930,257\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering\n",
      "\n",
      "Indoor User Movement Prediction from RSS Data\n",
      "\n",
      "Temporal wireless network data that can be used to track the movement of people in an office.\n",
      "\n",
      "None.\n",
      "\n",
      "13,197\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "PAMAP2 Physical Activity Monitoring Dataset\n",
      "\n",
      "18 different types of physical activities performed by 9 subjects wearing 3 IMUs.\n",
      "\n",
      "None.\n",
      "\n",
      "3,850,505\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "OPPORTUNITY Activity Recognition Dataset\n",
      "\n",
      "Human Activity Recognition from wearable, object, and ambient sensors is a dataset devised to benchmark human activity recognition algorithms.\n",
      "\n",
      "None.\n",
      "\n",
      "2551\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Real World Activity Recognition Dataset\n",
      "\n",
      "Human Activity Recognition from wearable devices. Distinguishes between seven on-body device positions and comprises six different kinds of sensors.\n",
      "\n",
      "None.\n",
      "\n",
      "3,150,000 (per sensor)\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Toronto Rehab Stroke Pose Dataset\n",
      "\n",
      "3D human pose estimates (Kinect) of stroke patients and healthy participants performing a set of tasks using a stroke rehabilitation robot.\n",
      "\n",
      "None.\n",
      "\n",
      "10 healthy person and 9 stroke survivors (3500-6000 frames per person)\n",
      "\n",
      "CSV\n",
      "\n",
      "Classification\n",
      "\n",
      "Wine Dataset\n",
      "\n",
      "Chemical analysis of wines grown in the same region in Italy but derived from three different cultivars.\n",
      "\n",
      "13 properties of each wine are given\n",
      "\n",
      "178\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, regression\n",
      "\n",
      "Combined Cycle Power Plant Data Set\n",
      "\n",
      "Data from various sensors within a power plant running for 6 years.\n",
      "\n",
      "None\n",
      "\n",
      "9568\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "HIGGS Dataset\n",
      "\n",
      "Monte Carlo simulations of particle accelerator collisions.\n",
      "\n",
      "28 features of each collision are given.\n",
      "\n",
      "11M\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "HEPMASS Dataset\n",
      "\n",
      "Monte Carlo simulations of particle accelerator collisions. Goal is to separate the signal from noise.\n",
      "\n",
      "28 features of each collision are given.\n",
      "\n",
      "10,500,000\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Yacht Hydrodynamics Dataset\n",
      "\n",
      "Yacht performance based on dimensions.\n",
      "\n",
      "Six features are given for each yacht.\n",
      "\n",
      "308\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "Robot Execution Failures Dataset\n",
      "\n",
      "5 data sets that center around robotic failure to execute common tasks.\n",
      "\n",
      "Integer valued features such as torque and other sensor measurements.\n",
      "\n",
      "463\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Pittsburgh Bridges Dataset\n",
      "\n",
      "Design description is given in terms of several properties of various bridges.\n",
      "\n",
      "Various bridge features are given.\n",
      "\n",
      "108\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Automobile Dataset\n",
      "\n",
      "Data about automobiles, their insurance risk, and their normalized losses.\n",
      "\n",
      "Car features extracted.\n",
      "\n",
      "205\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "Auto MPG Dataset\n",
      "\n",
      "MPG data for cars.\n",
      "\n",
      "Eight features of each car given.\n",
      "\n",
      "398\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "Energy Efficiency Dataset\n",
      "\n",
      "Heating and cooling requirements given as a function of building parameters.\n",
      "\n",
      "Building parameters given.\n",
      "\n",
      "768\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, regression\n",
      "\n",
      "Airfoil Self-Noise Dataset\n",
      "\n",
      "A series of aerodynamic and acoustic tests of two and three-dimensional airfoil blade sections.\n",
      "\n",
      "Data about frequency, angle of attack, etc., are given.\n",
      "\n",
      "1503\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "Challenger USA Space Shuttle O-Ring Dataset\n",
      "\n",
      "Attempt to predict O-ring problems given past Challenger data.\n",
      "\n",
      "Several features of each flight, such as launch temperature, are given.\n",
      "\n",
      "23\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "Statlog (Shuttle) Dataset\n",
      "\n",
      "NASA space shuttle datasets.\n",
      "\n",
      "Nine features given.\n",
      "\n",
      "58,000\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volcanoes on Venus â€“ JARtool experiment Dataset\n",
      "\n",
      "Venus images returned by the Magellan spacecraft.\n",
      "\n",
      "Images are labeled by humans.\n",
      "\n",
      "not given\n",
      "\n",
      "Images\n",
      "\n",
      "Classification\n",
      "\n",
      "MAGIC Gamma Telescope Dataset\n",
      "\n",
      "Monte Carlo generated high-energy gamma particle events.\n",
      "\n",
      "Numerous features extracted from the simulations.\n",
      "\n",
      "19,020\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Solar Flare Dataset\n",
      "\n",
      "Measurements of the number of certain types of solar flare events occurring in a 24-hour period.\n",
      "\n",
      "Many solar flare-specific features are given.\n",
      "\n",
      "1389\n",
      "\n",
      "Text\n",
      "\n",
      "Regression, classification\n",
      "\n",
      "Volcanoes of the World\n",
      "\n",
      "Volcanic eruption data for all known volcanic events on earth.\n",
      "\n",
      "Details such as region, subregion, tectonic setting, dominant rock type are given.\n",
      "\n",
      "1535\n",
      "\n",
      "Text\n",
      "\n",
      "Regression, classification\n",
      "\n",
      "Seismic-bumps Dataset\n",
      "\n",
      "Seismic activities from a coal mine.\n",
      "\n",
      "Seismic activity was classified as hazardous or not.\n",
      "\n",
      "2584\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Concrete Compressive Strength Dataset\n",
      "\n",
      "Dataset of concrete properties and compressive strength.\n",
      "\n",
      "Nine features are given for each sample.\n",
      "\n",
      "1030\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "Concrete Slump Test Dataset\n",
      "\n",
      "Concrete slump flow given in terms of properties.\n",
      "\n",
      "Features of concrete given such as fly ash, water, etc.\n",
      "\n",
      "103\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "Musk Dataset\n",
      "\n",
      "Predict if a molecule, given the features, will be a musk or a non-musk.\n",
      "\n",
      "168 features given for each molecule.\n",
      "\n",
      "6598\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Steel Plates Faults Dataset\n",
      "\n",
      "Steel plates of 7 different types.\n",
      "\n",
      "27 features given for each sample.\n",
      "\n",
      "1941\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "EEG Database\n",
      "\n",
      "Study to examine EEG correlates of genetic predisposition to alcoholism.\n",
      "\n",
      "Measurements from 64 electrodes placed on the scalp sampled at 256Â Hz (3.9Â ms epoch) for 1 second.\n",
      "\n",
      "122\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "P300 Interface Dataset\n",
      "\n",
      "Data from nine subjects collected using P300-based brain-computer interface for disabled subjects.\n",
      "\n",
      "Split into four sessions for each subject. MATLAB code given.\n",
      "\n",
      "1,224\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Breast Cancer Wisconsin (Diagnostic) Dataset\n",
      "\n",
      "Dataset of features of breast masses. Diagnoses by physician is given.\n",
      "\n",
      "10 features for each sample are given.\n",
      "\n",
      "569\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "National Survey on Drug Use and Health\n",
      "\n",
      "Large scale survey on health and drug use in the United States.\n",
      "\n",
      "None.\n",
      "\n",
      "55,268\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, regression\n",
      "\n",
      "Lung Cancer Dataset\n",
      "\n",
      "Lung cancer dataset without attribute definitions\n",
      "\n",
      "56 features are given for each case\n",
      "\n",
      "32\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Arrhythmia Dataset\n",
      "\n",
      "Data for a group of patients, of which some have cardiac arrhythmia.\n",
      "\n",
      "276 features for each instance.\n",
      "\n",
      "452\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Diabetes 130-US hospitals for years 1999â€“2008 Dataset\n",
      "\n",
      "9 years of readmission data across 130 US hospitals for patients with diabetes.\n",
      "\n",
      "Many features of each readmission are given.\n",
      "\n",
      "100,000\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering\n",
      "\n",
      "Diabetic Retinopathy Debrecen Dataset\n",
      "\n",
      "Features extracted from images of eyes with and without diabetic retinopathy.\n",
      "\n",
      "Features extracted and conditions diagnosed.\n",
      "\n",
      "1151\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Diabetic Retinopathy Messidor Dataset\n",
      "\n",
      "Methods to evaluate segmentation and indexing techniques in the field of retinal ophthalmology (MESSIDOR)\n",
      "\n",
      "Features retinopathy grade and risk of macular edema\n",
      "\n",
      "1200\n",
      "\n",
      "Images,Text\n",
      "\n",
      "Classification, Segmentation\n",
      "\n",
      "Liver Disorders Dataset\n",
      "\n",
      "Data for people with liver disorders.\n",
      "\n",
      "Seven biological features given for each patient.\n",
      "\n",
      "345\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Thyroid Disease Dataset\n",
      "\n",
      "10 databases of thyroid disease patient data.\n",
      "\n",
      "None.\n",
      "\n",
      "7200\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Mesothelioma Dataset\n",
      "\n",
      "Mesothelioma patient data.\n",
      "\n",
      "Large number of features, including asbestos exposure, are given.\n",
      "\n",
      "324\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Parkinson's Vision-Based Pose Estimation Dataset\n",
      "\n",
      "2D human pose estimates of Parkinson's patients performing a variety of tasks.\n",
      "\n",
      "Camera shake has been removed from trajectories.\n",
      "\n",
      "134\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, regression\n",
      "\n",
      "KEGG Metabolic Reaction Network (Undirected) Dataset\n",
      "\n",
      "Network of metabolic pathways. A reaction network and a relation network are given.\n",
      "\n",
      "Detailed features for each network node and pathway are given.\n",
      "\n",
      "65,554\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering, regression\n",
      "\n",
      "Modified Human Sperm Morphology Analysis Dataset (MHSMA)\n",
      "\n",
      "Human sperm images from 235 patients with male factor infertility, labeled for normal or abnormal sperm acrosome, head, vacuole, and tail.\n",
      "\n",
      "Cropped around single sperm head. Magnification normalized. Training, validation, and test set splits created.\n",
      "\n",
      "1,540\n",
      "\n",
      ".npy files\n",
      "\n",
      "Classification\n",
      "\n",
      "Abalone Dataset\n",
      "\n",
      "Physical measurements of Abalone. Weather patterns and location are also given.\n",
      "\n",
      "None.\n",
      "\n",
      "4177\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "Zoo Dataset\n",
      "\n",
      "Artificial dataset covering 7 classes of animals.\n",
      "\n",
      "Animals are classed into 7 categories and features are given for each.\n",
      "\n",
      "101\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Demospongiae Dataset\n",
      "\n",
      "Data about marine sponges.\n",
      "\n",
      "503 sponges in the Demosponge class are described by various features.\n",
      "\n",
      "503\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Splice-junction Gene Sequences Dataset\n",
      "\n",
      "Primate splice-junction gene sequences (DNA) with associated imperfect domain theory.\n",
      "\n",
      "None.\n",
      "\n",
      "3190\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Mice Protein Expression Dataset\n",
      "\n",
      "Expression levels of 77 proteins measured in the cerebral cortex of mice.\n",
      "\n",
      "None.\n",
      "\n",
      "1080\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, Clustering\n",
      "\n",
      "Forest Fires Dataset\n",
      "\n",
      "Forest fires and their properties.\n",
      "\n",
      "13 features of each fire are extracted.\n",
      "\n",
      "517\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "Iris Dataset\n",
      "\n",
      "Three types of iris plants are described by 4 different attributes.\n",
      "\n",
      "None.\n",
      "\n",
      "150\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Plant Species Leaves Dataset\n",
      "\n",
      "Sixteen samples of leaf each of one-hundred plant species.\n",
      "\n",
      "Shape descriptor, fine-scale margin, and texture histograms are given.\n",
      "\n",
      "1600\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Mushroom Dataset\n",
      "\n",
      "Mushroom attributes and classification.\n",
      "\n",
      "Many properties of each mushroom are given.\n",
      "\n",
      "8124\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Soybean Dataset\n",
      "\n",
      "Database of diseased soybean plants.\n",
      "\n",
      "35 features for each plant are given. Plants are classified into 19 categories.\n",
      "\n",
      "307\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Seeds Dataset\n",
      "\n",
      "Measurements of geometrical properties of kernels belonging to three different varieties of wheat.\n",
      "\n",
      "None.\n",
      "\n",
      "210\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering\n",
      "\n",
      "Covertype Dataset\n",
      "\n",
      "Data for predicting forest cover type strictly from cartographic variables.\n",
      "\n",
      "Many geographical features given.\n",
      "\n",
      "581,012\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Abscisic Acid Signaling Network Dataset\n",
      "\n",
      "Data for a plant signaling network. Goal is to determine set of rules that governs the network.\n",
      "\n",
      "None.\n",
      "\n",
      "300\n",
      "\n",
      "Text\n",
      "\n",
      "Causal-discovery\n",
      "\n",
      "Folio Dataset\n",
      "\n",
      "20 photos of leaves for each of 32 species.\n",
      "\n",
      "None.\n",
      "\n",
      "637\n",
      "\n",
      "Images, text\n",
      "\n",
      "Classification, clustering\n",
      "\n",
      "Oxford Flower Dataset\n",
      "\n",
      "17 category dataset of flowers.\n",
      "\n",
      "Train/test splits, labeled images,\n",
      "\n",
      "1360\n",
      "\n",
      "Images, text\n",
      "\n",
      "Classification\n",
      "\n",
      "Plant Seedlings Dataset\n",
      "\n",
      "12 category dataset of plant seedlings.\n",
      "\n",
      "Labelled images, segmented images,\n",
      "\n",
      "5544\n",
      "\n",
      "Images\n",
      "\n",
      "Classification, detection\n",
      "\n",
      "Fruits 360 dataset\n",
      "\n",
      "Database with images of 100 fruits.\n",
      "\n",
      "100x100 pixels, White background.\n",
      "\n",
      "69277\n",
      "\n",
      "Images (jpg)\n",
      "\n",
      "Classification\n",
      "\n",
      "Ecoli Dataset\n",
      "\n",
      "Protein localization sites.\n",
      "\n",
      "Various features of the protein localizations sites are given.\n",
      "\n",
      "336\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "MicroMass Dataset\n",
      "\n",
      "Identification of microorganisms from mass-spectrometry data.\n",
      "\n",
      "Various mass spectrometer features.\n",
      "\n",
      "931\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Yeast Dataset\n",
      "\n",
      "Predictions of Cellular localization sites of proteins.\n",
      "\n",
      "Eight features given per instance.\n",
      "\n",
      "1484\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Tox21 Dataset\n",
      "\n",
      "Prediction of outcome of biological assays.\n",
      "\n",
      "Chemical descriptors of molecules are given.\n",
      "\n",
      "12707\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Numenta Anomaly Benchmark (NAB)\n",
      "\n",
      "Data are ordered, timestamped, single-valued metrics. All data files contain anomalies, unless otherwise noted.\n",
      "\n",
      "None\n",
      "\n",
      "50+ files\n",
      "\n",
      "Comma separated values\n",
      "\n",
      "Anomaly detection\n",
      "\n",
      "On the Evaluation of Unsupervised Outlier Detection: Measures, Datasets, and an Empirical Study\n",
      "\n",
      "Most data files are adapted from UCI Machine Learning Repository data, some are collected from the literature.\n",
      "\n",
      "treated for missing values, numerical attributes only, different percentages of anomalies, labels\n",
      "\n",
      "1000+ files\n",
      "\n",
      "ARFF\n",
      "\n",
      "Anomaly detection\n",
      "\n",
      "DBpedia Neural Question Answering (DBNQA) Dataset\n",
      "\n",
      "A large collection of Question to SPARQL specially design for Open Domain Neural Question Answering over DBpedia Knowledgebase.\n",
      "\n",
      "This dataset contains a large collection of Open Neural SPARQL Templates and instances for training Neural SPARQL Machines; it was pre-processed by semi-automatic annotation tools as well as by three SPARQL experts.\n",
      "\n",
      "894,499\n",
      "\n",
      "Question-query pairs\n",
      "\n",
      "Question Answering\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dow Jones Index\n",
      "\n",
      "Weekly data of stocks from the first and second quarters of 2011.\n",
      "\n",
      "Calculated values included such as percentage change and a lags.\n",
      "\n",
      "750\n",
      "\n",
      "Comma separated values\n",
      "\n",
      "Classification, regression, Time series\n",
      "\n",
      "Statlog (Australian Credit Approval)\n",
      "\n",
      "Credit card applications either accepted or rejected and attributes about the application.\n",
      "\n",
      "Attribute names are removed as well as identifying information. Factors have been relabeled.\n",
      "\n",
      "690\n",
      "\n",
      "Comma separated values\n",
      "\n",
      "Classification\n",
      "\n",
      "eBay auction data\n",
      "\n",
      "Auction data from various eBay.com objects over various length auctions\n",
      "\n",
      "Contains all bids, bidderID, bid times, and opening prices.\n",
      "\n",
      "~ 550\n",
      "\n",
      "Text\n",
      "\n",
      "Regression, classification\n",
      "\n",
      "Statlog (German Credit Data)\n",
      "\n",
      "Binary credit classification into \"good\" or \"bad\" with many features\n",
      "\n",
      "Various financial features of each person are given.\n",
      "\n",
      "690\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Bank Marketing Dataset\n",
      "\n",
      "Data from a large marketing campaign carried out by a large bank .\n",
      "\n",
      "Many attributes of the clients contacted are given. If the client subscribed to the bank is also given.\n",
      "\n",
      "45,211\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Istanbul Stock Exchange Dataset\n",
      "\n",
      "Several stock indexes tracked for almost two years.\n",
      "\n",
      "None.\n",
      "\n",
      "536\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, regression\n",
      "\n",
      "Default of Credit Card Clients\n",
      "\n",
      "Credit default data for Taiwanese creditors.\n",
      "\n",
      "Various features about each account are given.\n",
      "\n",
      "30,000\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Cloud DataSet\n",
      "\n",
      "Data about 1024 different clouds.\n",
      "\n",
      "Image features extracted.\n",
      "\n",
      "1024\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering\n",
      "\n",
      "El Nino Dataset\n",
      "\n",
      "Oceanographic and surface meteorological readings taken from a series of buoys positioned throughout the equatorial Pacific.\n",
      "\n",
      "12 weather attributes are measured at each buoy.\n",
      "\n",
      "178080\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "Greenhouse Gas Observing Network Dataset\n",
      "\n",
      "Time-series of greenhouse gas concentrations at 2921 grid cells in California created using simulations of the weather.\n",
      "\n",
      "None.\n",
      "\n",
      "2921\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "Atmospheric CO2 from Continuous Air Samples at Mauna Loa Observatory\n",
      "\n",
      "Continuous air samples in Hawaii, USA. 44 years of records.\n",
      "\n",
      "None.\n",
      "\n",
      "44 years\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "Ionosphere Dataset\n",
      "\n",
      "Radar data from the ionosphere. Task is to classify into good and bad radar returns.\n",
      "\n",
      "Many radar features given.\n",
      "\n",
      "351\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Ozone Level Detection Dataset\n",
      "\n",
      "Two ground ozone level datasets.\n",
      "\n",
      "Many features given, including weather conditions at time of measurement.\n",
      "\n",
      "2536\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Adult Dataset\n",
      "\n",
      "Census data from 1994 containing demographic features of adults and their income.\n",
      "\n",
      "Cleaned and anonymized.\n",
      "\n",
      "48,842\n",
      "\n",
      "Comma separated values\n",
      "\n",
      "Classification\n",
      "\n",
      "Census-Income (KDD)\n",
      "\n",
      "Weighted census data from the 1994 and 1995 Current Population Surveys.\n",
      "\n",
      "Split into training and test sets.\n",
      "\n",
      "299,285\n",
      "\n",
      "Comma separated values\n",
      "\n",
      "Classification\n",
      "\n",
      "IPUMS Census Database\n",
      "\n",
      "Census data from the Los Angeles and Long Beach areas.\n",
      "\n",
      "None\n",
      "\n",
      "256,932\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, regression\n",
      "\n",
      "US Census Data 1990\n",
      "\n",
      "Partial data from 1990 US census.\n",
      "\n",
      "Results randomized and useful attributes selected.\n",
      "\n",
      "2,458,285\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, regression\n",
      "\n",
      "Bike Sharing Dataset\n",
      "\n",
      "Hourly and daily count of rental bikes in a large city.\n",
      "\n",
      "Many features, including weather, length of trip, etc., are given.\n",
      "\n",
      "17,389\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "New York City Taxi Trip Data\n",
      "\n",
      "Trip data for yellow and green taxis in New York City.\n",
      "\n",
      "Gives pick up and drop off locations, fares, and other details of trips.\n",
      "\n",
      "6 years\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering\n",
      "\n",
      "Taxi Service Trajectory ECML PKDD\n",
      "\n",
      "Trajectories of all taxis in a large city.\n",
      "\n",
      "Many features given, including start and stop points.\n",
      "\n",
      "1,710,671\n",
      "\n",
      "Text\n",
      "\n",
      "Clustering, causal-discovery\n",
      "\n",
      "Webpages from Common Crawl 2012\n",
      "\n",
      "Large collection of webpages and how they are connected via hyperlinks\n",
      "\n",
      "None.\n",
      "\n",
      "3.5B\n",
      "\n",
      "Text\n",
      "\n",
      "clustering, classification\n",
      "\n",
      "Internet Advertisements Dataset\n",
      "\n",
      "Dataset for predicting if a given image is an advertisement or not.\n",
      "\n",
      "Features encode geometry of ads and phrases occurring in the URL.\n",
      "\n",
      "3279\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Internet Usage Dataset\n",
      "\n",
      "General demographics of internet users.\n",
      "\n",
      "None.\n",
      "\n",
      "10,104\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering\n",
      "\n",
      "URL Dataset\n",
      "\n",
      "120 days of URL data from a large conference.\n",
      "\n",
      "Many features of each URL are given.\n",
      "\n",
      "2,396,130\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Phishing Websites Dataset\n",
      "\n",
      "Dataset of phishing websites.\n",
      "\n",
      "Many features of each site are given.\n",
      "\n",
      "2456\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Online Retail Dataset\n",
      "\n",
      "Online transactions for a UK online retailer.\n",
      "\n",
      "Details of each transaction given.\n",
      "\n",
      "541,909\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering\n",
      "\n",
      "Freebase Simple Topic Dump\n",
      "\n",
      "Freebase is an online effort to structure all human knowledge.\n",
      "\n",
      "Topics from Freebase have been extracted.\n",
      "\n",
      "large\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering\n",
      "\n",
      "Farm Ads Dataset\n",
      "\n",
      "The text of farm ads from websites. Binary approval or disapproval by content owners is given.\n",
      "\n",
      "SVMlight sparse vectors of text words in ads calculated.\n",
      "\n",
      "4143\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Poker Hand Dataset\n",
      "\n",
      "5 card hands from a standard 52 card deck.\n",
      "\n",
      "Attributes of each hand are given, including the Poker hands formed by the cards it contains.\n",
      "\n",
      "1,025,010\n",
      "\n",
      "Text\n",
      "\n",
      "Regression, classification\n",
      "\n",
      "Connect-4 Dataset\n",
      "\n",
      "Contains all legal 8-ply positions in the game of connect-4 in which neither player has won yet, and in which the next move is not forced.\n",
      "\n",
      "None.\n",
      "\n",
      "67,557\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Chess (King-Rook vs. King) Dataset\n",
      "\n",
      "Endgame Database for White King and Rook against Black King.\n",
      "\n",
      "None.\n",
      "\n",
      "28,056\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Chess (King-Rook vs. King-Pawn) Dataset\n",
      "\n",
      "King+Rook versus King+Pawn on a7.\n",
      "\n",
      "None.\n",
      "\n",
      "3196\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Tic-Tac-Toe Endgame Dataset\n",
      "\n",
      "Binary classification for win conditions in tic-tac-toe.\n",
      "\n",
      "None.\n",
      "\n",
      "958\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Housing Data Set\n",
      "\n",
      "Median home values of Boston with associated home and neighborhood attributes.\n",
      "\n",
      "None.\n",
      "\n",
      "506\n",
      "\n",
      "Text\n",
      "\n",
      "Regression\n",
      "\n",
      "The Getty Vocabularies\n",
      "\n",
      "structured terminology for art and other material culture, archival materials, visual surrogates, and bibliographic materials.\n",
      "\n",
      "None.\n",
      "\n",
      "large\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Yahoo! Front Page Today Module User Click Log\n",
      "\n",
      "User click log for news articles displayed in the Featured Tab of the Today Module on Yahoo! Front Page.\n",
      "\n",
      "Conjoint analysis with a bilinear model.\n",
      "\n",
      "45,811,883 user visits\n",
      "\n",
      "Text\n",
      "\n",
      "Regression, clustering\n",
      "\n",
      "British Oceanographic Data Centre\n",
      "\n",
      "Biological, chemical, physical and geophysical data for oceans. 22K variables tracked.\n",
      "\n",
      "Various.\n",
      "\n",
      "22K variables, many instances\n",
      "\n",
      "Text\n",
      "\n",
      "Regression, clustering\n",
      "\n",
      "Congressional Voting Records Dataset\n",
      "\n",
      "Voting data for all USA representatives on 16 issues.\n",
      "\n",
      "Beyond the raw voting data, various other features are provided.\n",
      "\n",
      "435\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Entree Chicago Recommendation Dataset\n",
      "\n",
      "Record of user interactions with Entree Chicago recommendation system.\n",
      "\n",
      "Details of each users usage of the app are recorded in detail.\n",
      "\n",
      "50,672\n",
      "\n",
      "Text\n",
      "\n",
      "Regression, recommendation\n",
      "\n",
      "Insurance Company Benchmark (COIL 2000)\n",
      "\n",
      "Information on customers of an insurance company.\n",
      "\n",
      "Many features of each customer and the services they use.\n",
      "\n",
      "9,000\n",
      "\n",
      "Text\n",
      "\n",
      "Regression, classification\n",
      "\n",
      "Nursery Dataset\n",
      "\n",
      "Data from applicants to nursery schools.\n",
      "\n",
      "Data about applicant's family and various other factors included.\n",
      "\n",
      "12,960\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "University Dataset\n",
      "\n",
      "Data describing attributed of a large number of universities.\n",
      "\n",
      "None.\n",
      "\n",
      "285\n",
      "\n",
      "Text\n",
      "\n",
      "Clustering, classification\n",
      "\n",
      "Blood Transfusion Service Center Dataset\n",
      "\n",
      "Data from blood transfusion service center. Gives data on donors return rate, frequency, etc.\n",
      "\n",
      "None.\n",
      "\n",
      "748\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Record Linkage Comparison Patterns Dataset\n",
      "\n",
      "Large dataset of records. Task is to link relevant records together.\n",
      "\n",
      "Blocking procedure applied to select only certain record pairs.\n",
      "\n",
      "5,749,132\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Nomao Dataset\n",
      "\n",
      "Nomao collects data about places from many different sources. Task is to detect items that describe the same place.\n",
      "\n",
      "Duplicates labeled.\n",
      "\n",
      "34,465\n",
      "\n",
      "Text\n",
      "\n",
      "Classification\n",
      "\n",
      "Movie Dataset\n",
      "\n",
      "Data for 10,000 movies.\n",
      "\n",
      "Several features for each movie are given.\n",
      "\n",
      "10,000\n",
      "\n",
      "Text\n",
      "\n",
      "Clustering, classification\n",
      "\n",
      "Open University Learning Analytics Dataset\n",
      "\n",
      "Information about students and their interactions with a virtual learning environment.\n",
      "\n",
      "None.\n",
      "\n",
      "~ 30,000\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, clustering, regression\n",
      "\n",
      "Mobile phone records\n",
      "\n",
      "Telecommunications activity and interactions\n",
      "\n",
      "Aggregation per geographical grid cells and every 15 minutes.\n",
      "\n",
      "large\n",
      "\n",
      "Text\n",
      "\n",
      "Classification, Clustering, Regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from elasticsearch import Elasticsearch\n",
    "import re\n",
    "import time\n",
    "es_client = Elasticsearch(['http://127.0.0.1:9200'])\n",
    "\n",
    "sitemap_feed = 'https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research'\n",
    "page = requests.get(sitemap_feed)\n",
    "soup = BeautifulSoup(page.text)\n",
    "\n",
    "tables = soup.findAll(\"table\", { \"class\" : \"wikitable\" })\n",
    "for table in tables:\n",
    "    table = table.find(\"tbody\")\n",
    "    for row in table.findAll(\"tr\"):\n",
    "        cells = row.findAll(\"td\")\n",
    "        i = 1\n",
    "        dataset_name = \"\"\n",
    "        description = \"\"\n",
    "        preprocessing = \"\"\n",
    "        instances = \"\"\n",
    "        formatt = \"\"\n",
    "        def_task = \"\"\n",
    "        for cell in cells:\n",
    "            print(cell.text)\n",
    "            if i == 1:\n",
    "                dataset_name = cell.text\n",
    "            if i == 2:\n",
    "                description = cell.text\n",
    "            if i == 3:\n",
    "                preprocessing = cell.text\n",
    "            if i == 4:\n",
    "                instances = cell.text\n",
    "            if i == 5:\n",
    "                formatt = cell.text\n",
    "            if i == 6:\n",
    "                def_task = cell.text\n",
    "            i+=1\n",
    "            if i > 6:\n",
    "                break\n",
    "        dataset = {\n",
    "            'dataset_name' : dataset_name,\n",
    "            'description' : description,\n",
    "            'preprocessing' : preprocessing,\n",
    "            'instances' : instances,\n",
    "            'format' : formatt,\n",
    "            'defaul_task' : def_task,\n",
    "            'url' : \"none\"\n",
    "        }\n",
    "\n",
    "    # ingest payload into elasticsearch\n",
    "        res = es_client.index(index=\"search\", doc_type=\"dataset\", body=dataset)\n",
    "        time.sleep(0.5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<td>Mobile phone records\n",
      "</td>, <td>Telecommunications activity and interactions\n",
      "</td>, <td>Aggregation per geographical grid cells and every 15 minutes.\n",
      "</td>, <td>large\n",
      "</td>, <td>Text\n",
      "</td>, <td>Classification, Clustering, Regression\n",
      "</td>, <td>2015\n",
      "</td>, <td><sup class=\"reference\" id=\"cite_ref-BarlacchiDe_Nadai2015_478-0\"><a href=\"#cite_note-BarlacchiDe_Nadai2015-478\">[478]</a></sup>\n",
      "</td>, <td>G. Barlacchi et al.\n",
      "</td>]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'split'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-d772636450e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcells\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcells\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcells\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1618\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1619\u001b[0m         raise AttributeError(\n\u001b[1;32m-> 1620\u001b[1;33m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1621\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'split'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import re\n",
    "import time\n",
    "es_client = Elasticsearch(['http://127.0.0.1:9200'])\n",
    "dataset = {\n",
    "            'dataset_name' : dataset_name,\n",
    "            'description' : description,\n",
    "            'preprocessing' : preprocessing,\n",
    "            'instances' : instances,\n",
    "            'format' : formatt,\n",
    "            'defaul_task' : def_task,\n",
    "            'url' : \"none\"\n",
    "        }\n",
    "res = es_client.index(index=\"search\", doc_type=\"dataset\", body=dataset)\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
