 chatcrazie overview this is our chatbot chatcrazie on youtube it starts with this video on youtube chatbot implemented using rnn and glove embeddings whch answers your query crazily to download glove embeddings go to this link problem statement main problem domain is building chatbot which is capable of generating the best response for any general user query the best reply must contain following attributes 1 answers to the user question 2 provides sender with relevant details 3 able to ask follow up questions and 4 able to continue the conversation in realistic manner in order to achieve this goal the chatbot needs to have understanding of the sender messages so that it can predict which sort of response will be relevant and it must be correct lexically and grammatically while generating the reply methodology data set acquisition it is the one of the most important step in designing chatbot after lots of research and fine tuning experimentation we have used gunthercox dataset and also modified it the dataset contains conversations based on various topics such as emotions psychology sports normal day to day conversations etc the better the dataset the more accurate and efficient conversational results can be obtained pre processing this step involves cleaning the dataset such as removing unwanted characters or or or etc and replacing them with blank spaces tokenization and vectorization basic tokenizer such as in nltk splits the text into minimal meaningful units called as tokens such as words and eliminates punctuation characters we have used glove global vectors for word representations which is an unsupervised learning algorithm that maps words to vectors of real numbers splitting train and test data we divided the total dataset into 80 training data and 20 validation data the chatbot was tested based on comparative study of review analysis from various users as how relevant they find the conversation to be with the chatbot creation of lstm encoder and decoder model lstm are special kind of rnn which are capable of learning long term dependencies encoder decoder model contains two parts encoder which takes the vector representation of input sequence and maps it to an encoded representation of the input this is then used by decoder to generate output train and save model we trained the model on modified gunthercox dataset with 250 epochs and batch size of 16 word embedding size was set to100 we took categorical crossentropy as our loss function and optimiser used was rmsprop we got the best results with these parameters we trained and tested our model on nvidia dgx 1 v100 training accuracy obtained was approximately 99 and validation accuracy of about 97 prediction finally the user can input one questions and converse with the chatbot the results obtained are satisfactory according to review analysis this project was done under the guidance of mr shreyans jain submitted by kushagra goel anushree jain akshita gupta 