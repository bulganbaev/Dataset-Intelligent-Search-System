
Siraj_Course_How-to-Do-Linear-Regression-using-Gradient-Descent
This is the code I wrote along with the "How to Do Linear Regression the Right Way" live session by Siraj Raval on Youtube
Overview
This is the code for this video on Youtube by Siraj Raval. I'm using a small dataset of student test scores and the amount of hours they studied. Intuitively, there must be a relationship right? The more you study, the better your test scores should be. We're going to use linear regression to prove this relationship.
Here are some helpful links:
Gradient descent visualization
https://raw.githubusercontent.com/mattnedrich/GradientDescentExample/master/gradient_descent_example.gif
Sum of squared distances formula (to calculate our error)
https://spin.atomicobject.com/wp-content/uploads/linear_regression_error1.png
Partial derivative with respect to b and m (to perform gradient descent)
https://spin.atomicobject.com/wp-content/uploads/linear_regression_gradient1.png
Dependencies

numpy

Python 2 and 3 both work for this. Use pip to install any dependencies.
Usage
Just run python3 demo.py to see the results:
Starting gradient descent at b = 0, m = 0, error = 5565.107834483211
Running...
After 1000 iterations b = 0.08893651993741346, m = 1.4777440851894448, error = 112.61481011613473

Credits
Credits for this code go to mattnedrich. I've merely created a wrapper to get people started.

