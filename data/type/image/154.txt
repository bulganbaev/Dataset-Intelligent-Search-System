
VGG Face Search
Author:

Ernesto Coto, University of Oxford â€“ ecoto@robots.ox.ac.uk

License: BSD (see LICENSE.md)
Overview
This repository includes a face-search service meant to serve requests generated by the vgg_frontend web interface. However, it could be easily adapted to server other clients. The source code for the service is located in the service folder. See the README file inside service for more information.
The repository also includes a data-ingestion pipeline mechanism to extract face-features from a user-defined dataset of images or a collection of videos. The output of this pipeline is then used by the face-search service to obtain the results of any search. The source code for the data-ingestion is located in the pipeline folder. See the README file inside pipeline for more information.
The two major dependencies are the face-detector and Caffe, in the case of ingesting videos ffmpeg is also a major dependency. They must be installed in the dependencies folder. See the LICENSE.md file for links to the license of these dependencies.
The Caffe model used for feature-extraction must be located in the models folder. For the Windows operating system, a Resnet-50-256D model is used. For macOS and Linux, a more accurate version is used: SE-Resnet-50-256D. Both models can be downloaded from the GitHub repository of VGGFace2. See the LICENSE.md file for links to the license of this model.
Supported platforms
Successfully deployed on Ubuntu 14 LTS, macOS High Sierra v10.13.3 and Windows10 x64.
Installation Instructions
The service can run with or without GPU support. However, a different face-detector is used on each case, so different dependencies are needed.
For the Windows operating system, DLib is used for face detection. Enabling GPU support depends on how DLib is deployed on the target computer.
For non-Windows operating systems:

Without GPU support: a CPU face-detector extracted from facenet is used, along with Caffe and pycaffe.
With GPU support: the GPU Faster R-CNN python implementation is used. This software includes its own version of Caffe, so there is no need to download another version.

In the install directory you will find installation scripts for Ubuntu and macOS, for the GPU-only and the CPU-only versions of the service. For having a service that supports both the GPU and the CPU just use the GPU-only installer and then download facenet into the dependencies folder. See the CPU-only installation script for the way to do it.
If you want to install the service in Windows, see the Windows installer for VFF to get a rough idea of how to do the deployment.
Usage
Before running the service for the first time, please check the service/settings.py file:

Check that the CUDA_ENABLED flag is set to False if you used the CPU-only installation script or set to True if you used the GPU-only installation.
Make sure that DEPENDENCIES_PATH points to the location of the place where the dependency libraries (e.g. Caffe) are installed.
Make sure that DATASET_FEATS_FILE points to the location of your dataset features file. If you do not have one, you won't be able to run the service until you run the feature computation pipeline. See the README in the pipeline directory.
Adjust MAX_RESULTS_RETURN as you wish.
Only change the rest of the settings if you really know what you are doing.

If you already have adjusted the settings and have a dataset feature file, you should be ready to start the service. To do so, start a command-line terminal and use it to go inside the service folder, then execute the start_backend_service.sh script (start_backend_service.bat for Windows). Use that script file to define or modify any environment variables required by your local setup.
The service should be reachable at the HOST and PORT specified in the settings.

